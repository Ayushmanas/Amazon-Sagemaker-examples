{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5160e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a1dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-south-1\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'bankapplicationawsbucket' ## < --- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "# Retreive region name \n",
    "myRegion = boto3.session.Session().region_name\n",
    "print(myRegion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78506642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "## Create S3 bucket if not created already\n",
    "\n",
    "## Access to S3 as a resource\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    if myRegion=='ap-south-1':\n",
    "        s3.create_bucket(Bucket=bucket_name,\n",
    "                         CreateBucketConfiguration={'LocationConstraint': 'ap-south-1'}\n",
    "                        )\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 Error', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f5c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://bankapplicationawsbucket/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained xgboost model will be\n",
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "output_path = \"s3://{}/{}/output\".format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af655a48",
   "metadata": {},
   "source": [
    "### Downloading the dataset and storing in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242cdd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "try:\n",
    "    urllib.request.urlretrieve(url=\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", filename=\"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error:',r)\n",
    "    \n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv', index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data Load error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f55eccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "### Train Test split\n",
    "import numpy as np\n",
    "\n",
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=123), [int(0.7*len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c51af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost-as-a-built-in-algo/train/train.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.path.join(prefix, 'train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22c9473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving train and test data into buckets\n",
    "# We start with train data\n",
    "import os\n",
    "\n",
    "## For running models from AWS Sagemaker, we need to put dependent variable as first column\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_yes', 'y_no'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fab09495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data into buckets\n",
    "\n",
    "## For running models from AWS Sagemaker, we need to put dependent variable as first column\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_yes', 'y_no'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9bb49",
   "metadata": {},
   "source": [
    "### Building XGboost model - In built algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70438581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "## Inbuilt algo present here are present as containers and images by sagemaker\n",
    "## We need to pull that image in our instance (Instance means my local system or the instance currently running in sagemaker)\n",
    "\n",
    "### This line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "## specify the repo version depending on your preference\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name,\n",
    "                         repo_name='xgboost',\n",
    "                         repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ab20022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do hyperparameter tuning as well, \n",
    "#but it might get into issues with billing, \n",
    "# as hyperparamter tunnig takes a lot of time which will be added in our bill\n",
    "\n",
    "# so here we are selecting the best parameter features, as per our data\n",
    "## Need to be key value rules\n",
    "hyperparameters = {\n",
    "    \"max_depth\":\"5\",\n",
    "    \"eta\":\"0.2\",\n",
    "    \"gamma\":\"4\",\n",
    "    \"min_child_weight\":\"6\",\n",
    "    \"subsample\":\"0.7\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":50\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39bd11cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a Sagemaker estimator that calls the xgboost-container\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1,\n",
    "                                          instance_type='ml.m5.2xlarge',\n",
    "                                          volume_size=5, # 5 GB\n",
    "                                          output_path=output_path,\n",
    "                                          use_spot_instances=True,\n",
    "                                          max_run=300,\n",
    "                                          max_wait = 600\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e2847e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-06-23-13-38-02-437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-23 13:38:02 Starting - Starting the training job...\n",
      "2024-06-23 13:38:30 Starting - Preparing the instances for training...\n",
      "2024-06-23 13:38:51 Downloading - Downloading input data...\n",
      "2024-06-23 13:39:06 Downloading - Downloading the training image...\n",
      "2024-06-23 13:40:02 Training - Training image download completed. Training in progress.\n",
      "2024-06-23 13:40:02 Uploading - Uploading generated training model\u001b[34m[2024-06-23 13:39:54.098 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34m[13:39:54] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[13:39:54] 12357x59 matrix with 729063 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2024-06-23 13:39:54.276 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-06-23 13:39:54.276 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-06-23 13:39:54.276 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-06-23 13:39:54.277 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-06-23 13:39:54.277 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 28831 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 12357 rows\u001b[0m\n",
      "\u001b[34m[13:39:54] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.10229#011validation-error:0.10229\u001b[0m\n",
      "\u001b[34m[2024-06-23 13:39:54.322 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO hook.py:423] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-06-23 13:39:54.324 ip-10-0-182-58.ap-south-1.compute.internal:7 INFO hook.py:486] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.10201#011validation-error:0.10286\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.10090#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.10079#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.10048#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.10045#011validation-error:0.10181\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.10024#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.10017#011validation-error:0.10100\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.09986#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.10003#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.10007#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.10003#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.10003#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.09975#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.09975#011validation-error:0.10100\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.09989#011validation-error:0.10132\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.09996#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.10000#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.09979#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.09996#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.09972#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.09975#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.09965#011validation-error:0.10075\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.09968#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.09975#011validation-error:0.10100\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09975#011validation-error:0.10100\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.09968#011validation-error:0.10075\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.09951#011validation-error:0.10083\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.09944#011validation-error:0.10100\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.09948#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.09958#011validation-error:0.10083\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.09982#011validation-error:0.10067\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.09965#011validation-error:0.10075\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.09989#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.09993#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09993#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.09986#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.09958#011validation-error:0.10067\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.09955#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.09951#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09944#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.09930#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.09944#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.09951#011validation-error:0.10140\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.09948#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.09948#011validation-error:0.10116\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.09951#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.09965#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.09951#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.09944#011validation-error:0.10205\u001b[0m\n",
      "\n",
      "2024-06-23 13:40:09 Completed - Training job completed\n",
      "Training seconds: 78\n",
      "Billable seconds: 34\n",
      "Managed Spot Training savings: 56.4%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train, 'validation':s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d06e2",
   "metadata": {},
   "source": [
    "### Deploy Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c364232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-06-23-13-44-48-795\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-06-23-13-44-48-795\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-06-23-13-44-48-795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56921f86",
   "metadata": {},
   "source": [
    "### Prediction of the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2fc3343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "test_data_array = test_data.drop(['y_no','y_yes'], axis=1).values  # load the data into array\n",
    "xgb_predictor.content_type = 'text/csv'  # set data type for an inference\n",
    "xgb_predictor.serializer = CSVSerializer() # set the serializer type\n",
    "\n",
    "predictions = xgb_predictor.predict(test_data_array).decode(\"utf-8\") # predict in string!\n",
    "predictions_array = np.fromstring(predictions, sep=',') # and then turn these predictions into array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "736e6683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357, 61)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(np.unique(np.round(predictions_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11b17f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.8%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    91% (10824)    37% (162)\n",
      "Purchase        9% (1099)     63% (272) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]\n",
    "tp = cm.iloc[1,1]\n",
    "fn = cm.iloc[1,0]\n",
    "fp = cm.iloc[0,1]\n",
    "\n",
    "acc = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", acc))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3fba71",
   "metadata": {},
   "source": [
    "### Deleting the endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "019d3e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-xgboost-2024-06-23-13-44-48-795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'RPVXDQYES5PDHNPW',\n",
       "   'HostId': 'FQD5uTIVRh3X5PRKNSOk3y2X054OE482TYedBeZqtkISzkUvQCYDEiGiDjAuruf+6EQdZsxis+Y=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'FQD5uTIVRh3X5PRKNSOk3y2X054OE482TYedBeZqtkISzkUvQCYDEiGiDjAuruf+6EQdZsxis+Y=',\n",
       "    'x-amz-request-id': 'RPVXDQYES5PDHNPW',\n",
       "    'date': 'Sun, 23 Jun 2024 17:26:24 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/index/000000000/000000000040_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/index/000000000/000000000010_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/claim.smd'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/events/000000000030/000000000030_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/output/model.tar.gz'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/events/000000000020/000000000020_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/profiler-output/system/incremental/2024062313/1719149880.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/index/000000000/000000000020_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/index/000000000/000000000030_worker_0.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/events/000000000040/000000000040_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/profiler-output/system/incremental/2024062313/1719149940.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/events/000000000010/000000000010_worker_0.tfevents'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/profiler-output/system/incremental/2024062313/1719150000.algo-1.json'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2024-06-23-13-38-02-437/debug-output/events/000000000000/000000000000_worker_0.tfevents'}]}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the endpoint as soon as its done, to have less billing\n",
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()  # Eveyrthing in the bucket will get deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fd92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
